{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________________\n",
    "\n",
    "## DEMO INTERFACE\n",
    "__________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a demonstartion of the trained models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________________\n",
    "\n",
    "## IMPORTS AND FUNCTIONS\n",
    "__________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### UNCOMMENT AND RUN ONCE\n",
    "# !pip install pandas\n",
    "# !pip install numpy\n",
    "# !pip install pickle\n",
    "# !pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "import os, sys\n",
    "sys.path.append(os.path.abspath('..'))  # Ensure the parent directory of notebooks is in the system path\n",
    "\n",
    "\n",
    "from models.PRNN import PRNN\n",
    "from utils.PRNN_utils import   batch_calculate_grads, check_conditions, check_all_conditions, train_and_val, prepare_folds, process_CVresults, tags2sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_1 = ['The', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog' ]\n",
    "tags_1     = ['DT', 'JJ',   'JJ',   'NN', 'OT',    'OT',  'DT', 'JJ', 'NN']\n",
    "\n",
    "sentence_2 = ['Red', 'bird', 'flies', 'in', 'the', 'bright', 'blue', 'sky']\n",
    "tags_2     = ['JJ',    'NN',  'OT',    'OT',  'DT', 'JJ',      'JJ',   'NN']\n",
    "\n",
    "sentence_3 = ['The', 'bright', 'stars', 'in', 'the', 'clear', 'night', 'sky', 'whispered', 'secrets', 'to', 'the', 'child']\n",
    "tags_3     = ['DT',  'JJ',     'NN',    'OT', 'DT',  'JJ',   'NN',      'NN', 'OT',         'NN',     'OT', 'DT',   'NN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def tokens_and_tags(sentence):\n",
    "    # Sample sentence\n",
    "    #sentence = \"The quick brown fox jumps over the lazy dog\"\n",
    "\n",
    "    # Tokenize the sentence\n",
    "    tokens = word_tokenize(sentence)\n",
    "\n",
    "    # Tag the tokens with POS\n",
    "    tagged_words = nltk.pos_tag(tokens)\n",
    "\n",
    "    # Define the set of desired POS tags\n",
    "    desired_tags = {'JJ', 'NN', 'DT'}\n",
    "\n",
    "    # Initialize lists to store words and tags separately\n",
    "    words = []\n",
    "    tags = []\n",
    "\n",
    "    # Iterate over tagged words and filter them\n",
    "    for word, tag in tagged_words:\n",
    "        if tag in desired_tags:\n",
    "            words.append(word)\n",
    "            tags.append(tag)\n",
    "        else:\n",
    "            words.append(word)\n",
    "            tags.append('OT')\n",
    "\n",
    "    # Print the lists of words and tags\n",
    "    # print(\"Words:\", words)\n",
    "    # print(\"Tags:\", tags)\n",
    "\n",
    "    return words, tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pos_tags(tags = ['NN', 'JJ', 'DT', 'OT']):\n",
    "\n",
    "    liss = []\n",
    "    pos_dict = {'NN':1, 'DT':2, 'JJ':3, 'OT':4}\n",
    "\n",
    "    for tag in tags:\n",
    "        liss.append(pos_dict[tag])\n",
    "    \n",
    "    return liss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_for_example(sentence, tags, model):\n",
    "\n",
    "    sent_pos_tags = create_pos_tags(tags)\n",
    "    x = tags2sentence(sent_pos_tags)\n",
    "\n",
    "    print(\"SENTENCE :  \\t\", end='')\n",
    "    print(sentence)\n",
    "    print(\"TAGS     :  \\t\", end='')\n",
    "    print(tags)\n",
    "    print(\"PREDICTION: \\t\", end='')\n",
    "    print(model.predict_tags(x))\n",
    "\n",
    "    return model.predict_tags(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_chunks(sentence, preds):\n",
    "    chunks = []\n",
    "    chunk = []\n",
    "    for i in range(len(preds)):\n",
    "        if preds[i] == 1:\n",
    "            if len(chunk) > 1:\n",
    "                chunks.append(\" \".join(chunk))\n",
    "            chunk = [sentence[i]]\n",
    "        elif preds[i] == 0 and chunk:\n",
    "            chunk.append(sentence[i])\n",
    "    if len(chunk) > 1:\n",
    "        chunks.append(\" \".join(chunk))\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________________\n",
    "\n",
    "## LOAD ALL PRETRAINED MODELS\n",
    "__________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = PRNN()  # Instantiate a model\n",
    "\n",
    "# Loading the dictionary from the file using pickle\n",
    "with open('../data/CVresults_data.pkl', 'rb') as f:\n",
    "    model_dict1 = pickle.load(f)\n",
    "\n",
    "P_best1, W_best1 = process_CVresults(CVresults_dict=model_dict1, summarize=False)\n",
    "model1.params = P_best1\n",
    "model1.w = W_best1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = PRNN()  # Instantiate a model\n",
    "\n",
    "# Loading the dictionary from the file using pickle\n",
    "with open('../data/CVresults_con_data.pkl', 'rb') as f:\n",
    "    model_dict2 = pickle.load(f)\n",
    "\n",
    "P_best2, W_best2 = process_CVresults(CVresults_dict=model_dict2, summarize=False)\n",
    "model2.params = P_best2\n",
    "model2.w = W_best2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = PRNN()  # Instantiate a model\n",
    "\n",
    "# Loading the dictionary from the file using pickle\n",
    "with open('../data/CVresults_data.pkl', 'rb') as f:\n",
    "    model_dict3 = pickle.load(f)\n",
    "\n",
    "P_best3, W_best3 = process_CVresults(CVresults_dict=model_dict3, summarize=False)\n",
    "model3.params = P_best3\n",
    "model3.w = W_best3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = PRNN()  # Instantiate a model\n",
    "\n",
    "# Loading the dictionary from the file using pickle\n",
    "with open('../data/CVresults_data_sigmoid.pkl', 'rb') as f:\n",
    "    model_dict4 = pickle.load(f)\n",
    "\n",
    "P_best4, W_best4 = process_CVresults(CVresults_dict=model_dict4, summarize=False)\n",
    "model4.params = P_best4\n",
    "model4.w = W_best4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model5 = PRNN()  # Instantiate a model\n",
    "\n",
    "# Loading the dictionary from the file using pickle\n",
    "with open('../data/CVresults_data_sigmoid.pkl', 'rb') as f:\n",
    "    model_dict5 = pickle.load(f)\n",
    "\n",
    "P_best5, W_best5 = process_CVresults(CVresults_dict=model_dict5, summarize=False)\n",
    "model5.params = P_best5\n",
    "model5.w = W_best5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model6 = PRNN()  # Instantiate a model\n",
    "\n",
    "# Loading the dictionary from the file using pickle\n",
    "with open('../data/CVresults_data.pkl', 'rb') as f:\n",
    "    model_dict6 = pickle.load(f)\n",
    "\n",
    "P_best6, W_best6 = process_CVresults(CVresults_dict=model_dict6, summarize=False)\n",
    "model6.params = P_best6\n",
    "model6.w = W_best6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________________\n",
    "\n",
    "## TEST THE MODEL\n",
    "__________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "one = 'The quick brown fox jums over the lazy frog'\n",
    "two = 'Little red happy hood bought a basket of apples'\n",
    "three = 'Red bird flies in the bright blue sky'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "sen = three\n",
    "sentence_0, tags_0 = tokens_and_tags(sen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP PERCEPTRON\n",
      "---------------MODEL 1---------------\n",
      "\n",
      "SENTENCE :  \t['Red', 'bird', 'flies', 'in', 'the', 'bright', 'blue', 'sky']\n",
      "TAGS     :  \t['JJ', 'NN', 'OT', 'OT', 'DT', 'JJ', 'NN', 'NN']\n",
      "PREDICTION: \t[1. 0. 1. 1. 1. 0. 0. 0.]\n",
      "CHUNKS: \t ['Red bird', 'the bright blue sky']\n",
      "\n",
      "---------------MODEL 2---------------\n",
      "\n",
      "SENTENCE :  \t['Red', 'bird', 'flies', 'in', 'the', 'bright', 'blue', 'sky']\n",
      "TAGS     :  \t['JJ', 'NN', 'OT', 'OT', 'DT', 'JJ', 'NN', 'NN']\n",
      "PREDICTION: \t[1. 0. 1. 1. 1. 0. 0. 0.]\n",
      "CHUNKS: \t ['Red bird', 'the bright blue sky']\n",
      "\n",
      "---------------MODEL 3---------------\n",
      "\n",
      "SENTENCE :  \t['Red', 'bird', 'flies', 'in', 'the', 'bright', 'blue', 'sky']\n",
      "TAGS     :  \t['JJ', 'NN', 'OT', 'OT', 'DT', 'JJ', 'NN', 'NN']\n",
      "PREDICTION: \t[1. 0. 1. 1. 1. 0. 0. 0.]\n",
      "CHUNKS: \t ['Red bird', 'the bright blue sky']\n",
      "\n",
      "SIGMOID PERCEPTRON\n",
      "---------------MODEL 4---------------\n",
      "SENTENCE :  \t['Red', 'bird', 'flies', 'in', 'the', 'bright', 'blue', 'sky']\n",
      "TAGS     :  \t['JJ', 'NN', 'OT', 'OT', 'DT', 'JJ', 'NN', 'NN']\n",
      "PREDICTION: \t[1. 0. 1. 1. 1. 0. 0. 0.]\n",
      "CHUNKS: \t ['Red bird', 'the bright blue sky']\n",
      "\n",
      "---------------MODEL 5---------------\n",
      "SENTENCE :  \t['Red', 'bird', 'flies', 'in', 'the', 'bright', 'blue', 'sky']\n",
      "TAGS     :  \t['JJ', 'NN', 'OT', 'OT', 'DT', 'JJ', 'NN', 'NN']\n",
      "PREDICTION: \t[1. 0. 1. 1. 1. 0. 0. 0.]\n",
      "CHUNKS: \t ['Red bird', 'the bright blue sky']\n",
      "\n",
      "---------------MODEL 6---------------\n",
      "SENTENCE :  \t['Red', 'bird', 'flies', 'in', 'the', 'bright', 'blue', 'sky']\n",
      "TAGS     :  \t['JJ', 'NN', 'OT', 'OT', 'DT', 'JJ', 'NN', 'NN']\n",
      "PREDICTION: \t[1. 0. 1. 1. 1. 0. 0. 0.]\n",
      "CHUNKS: \t ['Red bird', 'the bright blue sky']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentence = sentence_0\n",
    "tags = tags_0\n",
    "\n",
    "print(\"STEP PERCEPTRON\")\n",
    "for idx, model in enumerate([model1, model2, model3]):\n",
    "    print(f\"---------------MODEL {idx+1}---------------\\n\")\n",
    "    preds = predict_for_example(sentence=sentence, tags=tags, model=model1)\n",
    "    print(f'CHUNKS: \\t', find_chunks(sentence=sentence, preds=preds))\n",
    "    print()\n",
    "\n",
    "\n",
    "print(\"SIGMOID PERCEPTRON\")\n",
    "for idx, model in enumerate([model4, model5, model6]):\n",
    "    print(f\"---------------MODEL {idx+4}---------------\")\n",
    "    preds = predict_for_example(sentence=sentence, tags=tags, model=model1)\n",
    "    print(f'CHUNKS: \\t', find_chunks(sentence=sentence, preds=preds))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________________________________________\n",
    "__________________\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
